{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TARGET DETERMINATION FOR PIP MINER MODEL\n",
    "\n",
    "This experiment is an extension of the `parameters` experiment. Given the range of with stable Martin Ratio:\n",
    "- what cluster identity should be seleted? How can we combine them into a strategy?\n",
    "- what could be the exit strategy for the  strategy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries, Define the parameters\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta  # noqa\n",
    "import plotly.graph_objects as go  # noqa\n",
    "import quantstats as qt\n",
    "import seaborn as sns\n",
    "from quantminer import Miner\n",
    "\n",
    "logger = logging.getLogger('optuna')\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "data_dir = Path.cwd().parent / 'data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 0 : DATA PREPARATION AND MODEL TRAINING\n",
    "- Asset : EURUSD, 1-hour\n",
    "- Parameter\n",
    "  - n_pivots : 3; 4\n",
    "  - n_clusters : 16; 15 \n",
    "  - n_lookback : 8; 14\n",
    "  - hold_period : 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Price Data\n",
    "data_path = data_dir / 'eur_h1.parquet'\n",
    "raw_data = pd.read_parquet(data_path)\n",
    "\n",
    "# Clean the data\n",
    "data = raw_data.copy()\n",
    "data = data.dropna()\n",
    "\n",
    "# Feature Engineering\n",
    "data['returns'] = data['close'].diff().fillna(0)\n",
    "data['returns+1'] = data['returns'].shift(-1)\n",
    "\n",
    "# Prepare the training data\n",
    "train_daterange = pd.date_range('2010-01-01', '2021-12-31', freq='1h')\n",
    "train_df = data[data.index.isin(train_daterange)]\n",
    "train_data = np.array(train_df['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.722329145998637"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "n_pivots=3\n",
    "n_clusters = 24\n",
    "n_lookback=15\n",
    "hold_period=3\n",
    "\n",
    "miner = Miner(\n",
    "    n_pivots=n_pivots,\n",
    "    n_clusters=n_clusters,\n",
    "    n_lookback=n_lookback,\n",
    "    hold_period=hold_period,\n",
    "    model_type='sequential'\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "miner.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature for the predicted labels\n",
    "data['cluster_labels'] = miner.transform(data['close']).astype(int)\n",
    "train_df = data[data.index.isin(train_daterange)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Parameters\n",
    "# fig_base = go.Figure()\n",
    "# for _ in range(n_clusters):\n",
    "#     _signals = miner.apply_holding_period(data['cluster_labels'], selected_labels=[_])\n",
    "#     _signals = np.where(_signals != -1, 1, 0)\n",
    "#     _ret = data['returns'] * _signals\n",
    "\n",
    "#     _cumsum = np.cumsum(_ret)\n",
    "#     fig_base.add_trace(go.Scatter(x=_cumsum.index, y=_cumsum, mode='lines', name=f' CLusters {_}'))\n",
    "\n",
    "# fig_base.update_layout(title='Cluster Returns Over Time',\n",
    "#                   xaxis_title='Time',\n",
    "#                   yaxis_title='Cumulative Returns',\n",
    "#                   legend_title='Clusters',\n",
    "#                   hovermode='closest',\n",
    "#                   )\n",
    "\n",
    "# fig_base.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT ONE : STRATEGY SELECTION\n",
    "For this experiment, we would select the clusters that beat a benchmark (Buy-and-Hold)\n",
    "- Profit Factor : 1\n",
    "- Sharpe ratio : \n",
    "- Ulcer Performance Index : From base data\n",
    "- Average Drawdown : From base data\n",
    "\n",
    "#### PROCEDURE\n",
    "1. Compute and store the returns array and martin ratio for each label/cluster, that meet the requirement (beat the benchmark; the Buy-Hold returns). Map each return to the label and direction.\n",
    "2. Select the best label with by Martin ratio.\n",
    "3. Compute the drawdown correlation between the returns from best label and other labels/returns. Select and store returns from correlation below a threshold value (default = .4)\n",
    "4. Combine the returns based:\n",
    "  - STRATEGY 1 : based on precendence, in order of descending martin ratio\n",
    "  - STRATEGY 2 : concurrent returns are allowed\n",
    "\n",
    "5. Test strategies on test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def compute_drawdown_series(returns):\n",
    "    \"\"\" Compute entire drawdown series. \"\"\"\n",
    "    cummax = np.maximum.accumulate(returns + 1)\n",
    "    drawdowns = (cummax - (returns + 1)) / cummax\n",
    "    return drawdowns\n",
    "\n",
    "def drawdown_correlation(returns1, returns2):\n",
    "    \"\"\"Compute drawdown correlations and plot the results.\"\"\"\n",
    "    # Compute drawdown series for both return streams\n",
    "    drawdowns1 = compute_drawdown_series(pd.Series(returns1))\n",
    "    drawdowns2 = compute_drawdown_series(pd.Series(returns2))\n",
    "    \n",
    "    # Combine drawdowns into a DataFrame\n",
    "    data = np.column_stack([drawdowns1, drawdowns2])\n",
    "    df_drawdowns = pd.DataFrame(data, columns=['Strategy 1', 'Strategy 2'])\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = df_drawdowns.corr()\n",
    "    \n",
    "    # Plotting the correlation matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt=\".2f\")\n",
    "    plt.title(\"Drawdown Correlation Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Combined Strategies\n",
    "    # Calculate and plot the cumulative sum of the combined returns\n",
    "    s1 = pd.Series(returns1)\n",
    "    s2 = pd.Series(returns2)\n",
    "\n",
    "    _s1 = s1.copy()\n",
    "    _s2 = s2.copy()\n",
    "    _s1.loc[_s1 == 0] = np.nan\n",
    "    _s2.loc[_s2 == 0] = np.nan\n",
    "    combined_returns_s1 = _s1.combine_first(s2)  # return1 takes precedence over return2\n",
    "    combined_returns_s2 = _s2.combine_first(s1)  # return1 takes precedence over return2\n",
    "    cumulative_returns_1 = combined_returns_s1.cumsum()\n",
    "    cumulative_returns_2 = combined_returns_s2.cumsum()\n",
    "\n",
    "    plt.plot(np.cumsum(returns1))\n",
    "    plt.plot(np.cumsum(returns2))\n",
    "    plt.plot(cumulative_returns_1, label='Combined 1-Pred')\n",
    "    plt.plot(cumulative_returns_2, label='Combined 2-Pred')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return correlation_matrix\n",
    "\n",
    "def drawdown_correlation_matrix(*args):\n",
    "    \"\"\"Compute drawdown correlations for any number of labeled returns and plot the results.\"\"\"\n",
    "     # Dictionary to hold the drawdowns with labels\n",
    "    drawdowns_dict = {}\n",
    "    \n",
    "    # Compute drawdown series for each returns array in kwargs\n",
    "    for return_dict in args:\n",
    "        for label, returns in return_dict.items():\n",
    "            drawdown_series = compute_drawdown_series(pd.Series(returns))\n",
    "            drawdowns_dict[label] = drawdown_series\n",
    "\n",
    "    # Convert the dictionary of drawdowns to a DataFrame\n",
    "    df_drawdowns = pd.DataFrame(drawdowns_dict)\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = df_drawdowns.corr()\n",
    "    \n",
    "    # Plotting the correlation matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt=\".2f\")\n",
    "    plt.title(\"Drawdown Correlation Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    return correlation_matrix\n",
    "\n",
    "def x_matrix(*args, function=compute_drawdown_series):\n",
    "    \"\"\"Compute drawdown correlations for any number of labeled returns and plot the results.\"\"\"\n",
    "     # Dictionary to hold the drawdowns with labels\n",
    "    drawdowns_dict = {}\n",
    "    \n",
    "    # Compute drawdown series for each returns array in kwargs\n",
    "    for return_dict in args:\n",
    "        for label, returns in return_dict.items():\n",
    "            drawdown_series = function(pd.Series(returns))\n",
    "            drawdowns_dict[label] = drawdown_series\n",
    "\n",
    "    # Convert the dictionary of drawdowns to a DataFrame\n",
    "    df_drawdowns = pd.DataFrame(drawdowns_dict)\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = df_drawdowns.corr()\n",
    "    \n",
    "    # Plotting the correlation matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt=\".2f\")\n",
    "    plt.title(\"Drawdown Correlation Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    return correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_profit_factor : 1\n",
      "baseline_sharpe_ratio : 0\n",
      "baseline_upi : 1\n",
      "baseline_max_dd : -0.3915354898763782\n"
     ]
    }
   ],
   "source": [
    "# Baseline Metrics\n",
    "baseline_returns = train_df['close'].diff().fillna(0)\n",
    "baseline_profit_factor = max(qt.stats.profit_factor(baseline_returns), 1)\n",
    "baseline_sharpe_ratio = max(qt.stats.sharpe(baseline_returns), 0)\n",
    "baseline_upi = max(qt.stats.ulcer_performance_index(baseline_returns), 1)\n",
    "baseline_max_dd = qt.stats.max_drawdown(baseline_returns) # not added yet\n",
    "\n",
    "print(f\"baseline_profit_factor : {baseline_profit_factor}\" )\n",
    "print(f\"baseline_sharpe_ratio : {baseline_sharpe_ratio}\" )\n",
    "print(f\"baseline_upi : {baseline_upi}\" )\n",
    "print(f\"baseline_max_dd : {baseline_max_dd}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['label_1_long', 'label_2_long', 'label_7_long', 'label_16_long', 'label_19_long', 'label_23_long']),\n",
       " dict_keys(['label_4_short', 'label_9_short', 'label_17_short', 'label_18_short']))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter clusters per performance\n",
    "cluster_results = {\n",
    "    'name' : [],\n",
    "    'label' : [],\n",
    "    'direction' : [],\n",
    "    'profit_factor' : [],\n",
    "    'sharpe_ratio': [],\n",
    "    'upi' :[],\n",
    "    'max_dd' : [], \n",
    "}\n",
    "\n",
    "returns_long = {}\n",
    "returns_short = {}\n",
    "\n",
    "# For each cluster label\n",
    "for cluster_label in range(n_clusters):\n",
    "    _signals :np.ndarray = miner.apply_holding_period(train_df['cluster_labels'], selected_labels=[cluster_label])\n",
    "    _signals = _signals != -1\n",
    "    _signals = _signals.astype(int)\n",
    "\n",
    "    # Test the returns as a Long and Short model\n",
    "    for direction in [1, -1]:\n",
    "        model_name = f\"label_{cluster_label}_{'long' if direction > 0 else 'short'}\"\n",
    "        \n",
    "        # Compute the returns\n",
    "        _ret = train_df['returns'] * _signals * direction\n",
    "\n",
    "        # Compute the kpis\n",
    "        _pf = qt.stats.profit_factor(_ret)\n",
    "        _sharpe = qt.stats.rolling_sharpe(_ret).mean()\n",
    "        _upi = qt.stats.ulcer_performance_index(_ret)\n",
    "        _max_dd = qt.stats.to_drawdown_series(_ret).mean()\n",
    "\n",
    "        # Append results\n",
    "        if ((_pf > baseline_profit_factor) and\n",
    "            (_sharpe > baseline_sharpe_ratio) and\n",
    "            (_upi > baseline_upi) and \n",
    "            (_max_dd > baseline_max_dd)):\n",
    "\n",
    "            cluster_results['name'].append(model_name)\n",
    "            cluster_results['label'].append(cluster_label)\n",
    "            cluster_results['direction'].append(direction)\n",
    "            cluster_results['profit_factor'].append(_pf)\n",
    "            cluster_results['sharpe_ratio'].append(_sharpe)\n",
    "            cluster_results['upi'].append(_upi)\n",
    "            cluster_results['max_dd'].append(_max_dd)\n",
    "\n",
    "            if direction > 0:\n",
    "                returns_long[model_name] = _ret\n",
    "            else:\n",
    "                returns_short[model_name] = _ret\n",
    "\n",
    "# Convert cluster_results into a dataframe\n",
    "cluster_performance = pd.DataFrame(cluster_results)\n",
    "returns_long.keys(), returns_short.keys()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best label with by Martin ratio.\n",
    "best_label = cluster_performance.sort_values('upi').iloc[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = data[(data.index.year >= train_daterange_start) & (data.index.year <= train_daterange_end)]\n",
    "# test_data = data[(data.index.year > train_daterange_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.Figure()\n",
    "\n",
    "# for cluster_index in range(n_clusters):\n",
    "#     cluster_backtest = train_data.loc[train_data['cluster_labels'] == cluster_index, 'returns+1']\n",
    "#     cumsum_backtest = np.cumsum(cluster_backtest)\n",
    "#     fig.add_trace(go.Scatter(x=cumsum_backtest.index, y=cumsum_backtest, mode='lines', name=f'Cluster {cluster_index}'))\n",
    "\n",
    "# fig.update_layout(title='Cluster Returns Over Time',\n",
    "#                   xaxis_title='Time',\n",
    "#                   yaxis_title='Cumulative Returns',\n",
    "#                   legend_title='Clusters',\n",
    "#                   hovermode='closest',\n",
    "#                   height=600)\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(-1, n_clusters):\n",
    "#     backtest_insample = train_data.loc[train_data['cluster_labels'] == _, 'returns+1']\n",
    "#     backtest_outsample = test_data.loc[test_data['cluster_labels'] == _, 'returns+1']\n",
    "\n",
    "#     print(F\"\\n\\n----- CLUSTER {_} -----\")\n",
    "#     print(f\"IN-SAMPLE :\\n\\tLONG :{qt.stats.sharpe(backtest_insample)}\\n\\tSHORT :{qt.stats.sharpe(backtest_insample * -1)}\")\n",
    "#     print(f\"OUT-OF-SAMPLE :\\n\\tLONG :{qt.stats.sharpe(backtest_outsample)}\\n\\tSHORT :{qt.stats.sharpe(backtest_outsample * -1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 78520702f91b371079341dd3fb343d534ab0ec9c\n",
    "# concluded  the `pipminer/parameters` experiment; made progress on the `pipminer/targets/strategyselection` experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
